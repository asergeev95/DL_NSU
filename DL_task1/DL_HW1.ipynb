{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, concatenate, Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read initial data via parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Сергеев\\Desktop\\DL_task1\\src\\helpers.py:23: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  data_train = pd.concat([df, data_train], ignore_index=True)\n",
      "C:\\Users\\Сергеев\\Desktop\\DL_task1\\src\\helpers.py:26: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  data_test = pd.concat([df, data_test], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = get_parsed_data()\n",
    "data_train.drop(['date', 'id', 'twitid'], axis=1, inplace = True, errors='ignore')\n",
    "data_train.fillna(0)\n",
    "\n",
    "data_train['label'] = data_train.apply(define_label, axis=1)\n",
    "data_test['label'] = data_test.apply(define_label, axis=1)\n",
    "data_train['clear_text'] = data_train.text.apply(clear_text)\n",
    "data_test['clear_text'] = data_test.text.apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(data_train.text)\n",
    "X_test = vectorizer.transform(data_test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn log regression model training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, data_train.label)\n",
    "model.score(X_test, data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data_train, data_test], ignore_index=True)\n",
    "split_text = data.clear_text.apply(lambda sent: sent.lower().split())\n",
    "w2v = Word2Vec(sentences=split_text, sg=1, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform data to index sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data.clear_text)\n",
    "X_train = tokenizer.texts_to_sequences(data_train.clear_text)\n",
    "X_test = tokenizer.texts_to_sequences(data_test.clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=30)\n",
    "X_test = pad_sequences(X_test, maxlen=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embeding matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "oov = []\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v.wv.vocab:\n",
    "        embedding_vector = w2v.wv.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        oov.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = len(list(w2v.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_input = Input(shape=(30,), dtype='int32')\n",
    "inp = Embedding(NUM+1, 100, input_length=30,\n",
    "                weights=[embedding_matrix], trainable=False)(tweet_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = []\n",
    "\n",
    "for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
    "    for i in range(filters_count):\n",
    "        # Добавляем слой свертки\n",
    "        branch = Conv1D(filters=1, kernel_size=size, padding='valid', activation='relu')(inp)\n",
    "        # Добавляем слой субдискретизации\n",
    "        branch = GlobalMaxPooling1D()(branch)\n",
    "        branches.append(branch)\n",
    "x = concatenate(branches, axis=1) \n",
    "drop_1 = Dropout(0.2)(x)\n",
    "hidden = Dense(30, activation='relu')(drop_1)\n",
    "drop_3 = Dropout(0.2)(hidden)\n",
    "out = Dense(3, activation='relu')(drop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=tweet_input, output=out) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18035/18035 [==============================] - 56s 3ms/step - loss: 0.8625 - acc: 0.6487\n",
      "Epoch 2/10\n",
      "18035/18035 [==============================] - 50s 3ms/step - loss: 0.7415 - acc: 0.6773\n",
      "Epoch 3/10\n",
      "18035/18035 [==============================] - 51s 3ms/step - loss: 0.7239 - acc: 0.6948\n",
      "Epoch 4/10\n",
      "18035/18035 [==============================] - 50s 3ms/step - loss: 0.7144 - acc: 0.7047\n",
      "Epoch 5/10\n",
      "18035/18035 [==============================] - 52s 3ms/step - loss: 0.6933 - acc: 0.7143\n",
      "Epoch 6/10\n",
      "18035/18035 [==============================] - 48s 3ms/step - loss: 0.7034 - acc: 0.7077\n",
      "Epoch 7/10\n",
      "18035/18035 [==============================] - 49s 3ms/step - loss: 0.6982 - acc: 0.6983\n",
      "Epoch 8/10\n",
      "18035/18035 [==============================] - 49s 3ms/step - loss: 0.6813 - acc: 0.7180\n",
      "Epoch 9/10\n",
      "18035/18035 [==============================] - 49s 3ms/step - loss: 0.6643 - acc: 0.7220\n",
      "Epoch 10/10\n",
      "18035/18035 [==============================] - 50s 3ms/step - loss: 0.6620 - acc: 0.7254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cacbe9940>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train], y=to_categorical(data_train.label.as_matrix()+1), verbose=1, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5560/5560 [==============================] - 8s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.816078743177781, 0.6366906474820144]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, to_categorical(data_test.label.values+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = model.predict(X_test)\n",
    "y_[-1] = [0,0,1]\n",
    "to_categorical([np.argmax(x) for x in y_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.440960916185547"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(to_categorical([np.argmax(x) for x in y_]), to_categorical(data_test.label.as_matrix()+1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6368705035971223"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(to_categorical([np.argmax(x) for x in y_]), to_categorical(data_test.label.as_matrix()+1), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
